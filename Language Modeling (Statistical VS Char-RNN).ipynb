{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vr4atkrm_QF-"
   },
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(random_seed)\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "# Включаем куду\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMOZs2ij4uKL"
   },
   "source": [
    "\n",
    "## Погружение в Natural Language Proccessing\n",
    "\n",
    "Так как обработкой языка занимались давно, а нейронные сети пытаются вставить везде лишь лет 10, то прежде чем решать задачи с помощью NN хотелось бы попробовать решить ее классическими методами. \n",
    "\n",
    "\n",
    "В данном задании мы будем всеми силами пытаться построить языковую модель (language model). \n",
    "\n",
    "\n",
    "#### Что это за модель? \n",
    "\n",
    "Тут везде почему-то говорится про какую-то неведомую модель. Уточню, вообще говоря, модель (в статистическом смысле, конечно) является математическим представлением процесса. Почти всегда модели являются приближением процесса. Для этого есть несколько причин, но два наиболее важных:\n",
    "1. Обычно мы наблюдаем только процесс ограниченное количество раз\n",
    "2. Модель может быть исключительно сложной, поэтому мы ее упрощаем\n",
    "\n",
    "Вот что обычно делает модель: она описывает, как моделируемый процесс __создает данные__. В нашем случае моделируемым явлением является человеческий язык. Языковая модель дает нам способ генерации человеческого языка. Эти модели обычно составлены из вероятностных распределений.\n",
    "\n",
    "Модель построена путем наблюдения некоторых образцов, сгенерированных явлением, которое должно быть смоделировано. Таким же образом, языковая модель строится путем наблюдения за некоторым текстом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k4fQPdp34uKN"
   },
   "source": [
    "### Bag Of Words\n",
    "\n",
    "Попробуем закодить для настоящего корпуса собраний сочинений Федора Михайловича Достоевского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "f_V0UqK-6UJy",
    "outputId": "87048907-e504-47a7-e7f9-c85812755a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-30 16:56:24--  https://raw.githubusercontent.com/DLSchool/dlschool_old/master/materials/homeworks/hw09/dostoevsky.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20406049 (19M) [text/plain]\n",
      "Saving to: ‘dostoevsky.txt’\n",
      "\n",
      "dostoevsky.txt      100%[===================>]  19.46M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2020-05-30 16:56:33 (205 MB/s) - ‘dostoevsky.txt’ saved [20406049/20406049]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DLSchool/dlschool_old/master/materials/homeworks/hw09/dostoevsky.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0o5du4f4uKN"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "with io.open('dostoevsky.txt', 'r',encoding='utf8') as f:\n",
    "    text = f.read().replace(u'\\xa0', u' ').replace(u'\\ufeff','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6gCrqQz-4uKQ",
    "outputId": "2f65124c-78f9-4c6c-b411-173a2608b50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n",
    "words = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0K9gpI6-q5e"
   },
   "source": [
    "1. Сколько слов и предложений в датасете?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDLvolAj4uKT"
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sents_full = sent_tokenize(text)\n",
    "sents = [word_tokenize(s) for s in sents_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XMSk29Tc91Jt",
    "outputId": "ede985c0-f7f9-4645-8ab7-1a4c2a04c5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во предложений:  123548\n",
      "Кол-во слов:  2305025\n"
     ]
    }
   ],
   "source": [
    "print('Кол-во предложений: ', len(sents_full))\n",
    "print('Кол-во слов: ', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "LNXv4hMa4uKV",
    "outputId": "542fb15b-041f-456a-8108-b99de8a6b2b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 265751), ('.', 85110), ('и', 80477), ('—', 53930), ('не', 39621), ('в', 39218), ('что', 34282), ('я', 25127), ('!', 22568), ('на', 20863), ('с', 19459), ('?', 18314), ('он', 17170), ('как', 14967), (';', 14015), ('это', 12030), ('его', 11939), ('а', 11840), ('же', 11689), ('все', 10566)]\n",
      "1.0\n",
      "[(',', 0.11529202503226646), ('.', 0.03692367761737942), ('и', 0.03491372110931552), ('—', 0.02339670936323901), ('не', 0.01718896758169651), ('в', 0.017014132167763908), ('что', 0.01487272372317003), ('я', 0.010900966366959143), ('!', 0.00979078318022581), ('на', 0.009051094890510949), ('с', 0.008441990867778007), ('?', 0.00794525005151788), ('он', 0.0074489430700317785), ('как', 0.0064932050628518125), (';', 0.0060801943579787635), ('это', 0.0052190323315365345), ('его', 0.00517955336710014), ('а', 0.005136603724471535), ('же', 0.005071094673593562), ('все', 0.004583898222362014)]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "from collections import Counter\n",
    " \n",
    "counts = Counter(words)\n",
    "total_count = len(words)\n",
    "\n",
    "# 20 наиболее популярных слов \n",
    "print(counts.most_common(n=20))\n",
    " \n",
    "\n",
    "# Частота в данном контексте является вероятностью появления слова (независимой)\n",
    "# Поэтому проверяем основное свойство - суммирование  в 1\n",
    "\n",
    "for word in counts:\n",
    "    counts[word] /= float(total_count)\n",
    "\n",
    "print(round(sum(counts.values()),3))  # 1.0\n",
    "\n",
    "\n",
    "print(counts.most_common(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0bYgFTrzApYU"
   },
   "source": [
    "2. Каковы частоты для слов \"бесы\", '\"семья\", \"брат\"'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UYnj1iM2dt35",
    "outputId": "c3b61d43-fa27-44c6-b7a0-3560765f4303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1e-05, 0.00022]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[round(i,5) for i in [counts['бесы'], counts['семья'], counts['брат']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3eaOBe8sqS7y",
    "outputId": "9ffbada7-40c8-4b57-c669-4e603d144afe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2305025"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s5pXCTmR4uKX",
    "outputId": "c6d30a39-491c-4d05-9f1c-759533952676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ходила , . там кровь « поспешал , ? , — он , : тем человеку — под неудовольствием ! столь столе так в попроще у , , участвовать Чего\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    " \n",
    "# Код для генерации текста уже имеющейся моделью\n",
    "new_text = []\n",
    " \n",
    "for _ in range(30):\n",
    "    accumulator = .0\n",
    "    r = random.random()\n",
    "    for word, freq in counts.items():\n",
    "        accumulator += freq\n",
    " \n",
    "        if accumulator >= r:\n",
    "            new_text.append(word)\n",
    "            break\n",
    "\n",
    "print(' '.join(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YJGJ5SyN_689"
   },
   "source": [
    "3. Генерируем текст, который состои из 10 слов с вероятностями появления от 0.85 до 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7a3ZK7qq5-1o",
    "outputId": "7c1e82c6-d536-47b0-9c2b-dcafbf52b9b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "веселы темный чистая письму недостает тесно весела окнами ошиблись старым\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    " \n",
    "for _ in range(10):\n",
    "    for word, freq in counts.items():\n",
    "      if freq > (0.85/100000) and freq < (0.95/100000) and word not in new_text: # and word not in new_text and word not in string.punctuation:\n",
    "          new_text.append(word)\n",
    "          #print (word, freq)\n",
    "          break\n",
    "\n",
    "print(' '.join(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNRpkUBV4uKZ"
   },
   "source": [
    "Как вы можете видеть, это не самый выразительный фрагмент контента. Полученный текст следует только частотным правилам языка и не более того.\n",
    "\n",
    "\n",
    "#### Биграммы,  триграммы и n-граммы\n",
    "\n",
    "Одна идея, которая может помочь нам создать более качественный текст, состоит в том, чтобы убедиться, что новое слово, которое мы добавляем в последовательность, хорошо сочетается с уже существующими словами. Проверка правильности слова после 10 слов может немного переборщить. Мы можем упростить все, чтобы проблема была разумной. Давайте сделаем так, чтобы новое слово получилось после последнего слова в последовательности (модель биграмм) или двух последних слов (модель триграмм) (можно так долго продолжать, из эмпирических наблюдений при n=5 модель всегда выдает нормальный текст ) .\n",
    "\n",
    "Некоторые быстрые магии NLTK (библиотека для nlp) для извлечения биграмм / триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "-kC3rxCw4uKd",
    "outputId": "7ec10fd5-8cff-4897-d615-6d48643386ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Федор', 'Михайлович', 'Достоевский', 'Бедные', 'люди', 'Ох', 'уж', 'эти', 'мне', 'сказочники', '!']\n",
      "[('Федор', 'Михайлович'), ('Михайлович', 'Достоевский'), ('Достоевский', 'Бедные'), ('Бедные', 'люди'), ('люди', 'Ох'), ('Ох', 'уж'), ('уж', 'эти'), ('эти', 'мне'), ('мне', 'сказочники'), ('сказочники', '!')]\n",
      "[(None, 'Федор'), ('Федор', 'Михайлович'), ('Михайлович', 'Достоевский'), ('Достоевский', 'Бедные'), ('Бедные', 'люди'), ('люди', 'Ох'), ('Ох', 'уж'), ('уж', 'эти'), ('эти', 'мне'), ('мне', 'сказочники'), ('сказочники', '!'), ('!', None)]\n",
      "[('Федор', 'Михайлович', 'Достоевский'), ('Михайлович', 'Достоевский', 'Бедные'), ('Достоевский', 'Бедные', 'люди'), ('Бедные', 'люди', 'Ох'), ('люди', 'Ох', 'уж'), ('Ох', 'уж', 'эти'), ('уж', 'эти', 'мне'), ('эти', 'мне', 'сказочники'), ('мне', 'сказочники', '!')]\n",
      "[(None, None, 'Федор'), (None, 'Федор', 'Михайлович'), ('Федор', 'Михайлович', 'Достоевский'), ('Михайлович', 'Достоевский', 'Бедные'), ('Достоевский', 'Бедные', 'люди'), ('Бедные', 'люди', 'Ох'), ('люди', 'Ох', 'уж'), ('Ох', 'уж', 'эти'), ('уж', 'эти', 'мне'), ('эти', 'мне', 'сказочники'), ('мне', 'сказочники', '!'), ('сказочники', '!', None), ('!', None, None)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    " \n",
    "first_sentence = word_tokenize(sents_full[0])\n",
    "print(first_sentence)\n",
    "\n",
    "# Get the bigrams\n",
    "print(list(bigrams(first_sentence)))\n",
    "\n",
    "# Get the padded bigrams\n",
    "print(list(bigrams(first_sentence, pad_left=True, pad_right=True)))\n",
    " \n",
    "# Get the trigrams\n",
    "print(list(trigrams(first_sentence)))\n",
    " \n",
    "# Get the padded trigrams\n",
    "print(list(trigrams(first_sentence, pad_left=True, pad_right=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xb50ohuh4uKg"
   },
   "source": [
    "Теперь можно и модель над этими биграммами построить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoTmzV-J4uKi"
   },
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    " \n",
    "for sentence in sents:\n",
    "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "        model[(w1, w2)][w3] += 1\n",
    "        \n",
    "# следует теперь привести количество встречаемостей к частотам\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSiiV7qLMk-I"
   },
   "outputs": [],
   "source": [
    "# следует теперь привести количество встречаемостей к частотам\n",
    "import itertools\n",
    "for w1_w2 in itertools.islice(model,1):\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    print (w1_w2, total_count)\n",
    "    for w3 in model[w1_w2]:\n",
    "      print (w3)\n",
    "      print (model[w1_w2][w3])     \n",
    "      #model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZmbPbpcIgyZ"
   },
   "outputs": [],
   "source": [
    "w1_w2 = ('Михайлович', 'Достоевский')\n",
    "total_count = float(sum(model[w1_w2].values()))\n",
    "print (total_count)\n",
    "for w3 in model[w1_w2]:\n",
    "  print (w3)\n",
    "  print (model[w1_w2][w3])\n",
    "  print(model[w1_w2][w3] / total_count)\n",
    "  model[w1_w2][w3] /= total_count\n",
    "\n",
    "model[w1_w2] \n",
    "#model[('чтоб', 'еще')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUhA9Q3VA8T0"
   },
   "source": [
    "4. Какова вероятность слова $w_3$ при условии $w_1, w_2$\n",
    "\n",
    "Берем соответсвующие им биграммы: {[чтоб еще], [мухи, сочинили], [прямо, по]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "FQUrW459R_ks",
    "outputId": "8ecda1e7-eb10-47f1-aa93-c55c51104d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность \" вам \" при ('чтоб', 'еще') :  0\n",
      "Вероятность \" вам \" при ('мухи', 'сочинили') :  0\n",
      "Вероятность \" вам \" при ('прямо', 'по') :  0\n",
      "Вероятность \" слона \" при ('чтоб', 'еще') :  0\n",
      "Вероятность \" слона \" при ('мухи', 'сочинили') :  1.0\n",
      "Вероятность \" слона \" при ('прямо', 'по') :  0\n",
      "Вероятность \" коридорчику \" при ('чтоб', 'еще') :  0\n",
      "Вероятность \" коридорчику \" при ('мухи', 'сочинили') :  0\n",
      "Вероятность \" коридорчику \" при ('прямо', 'по') :  0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "for w3 in ['вам', 'слона', 'коридорчику']:\n",
    "  for w1_w2 in [('чтоб', 'еще'), ('мухи', 'сочинили'), ('прямо', 'по')]:\n",
    "    print('Вероятность \"', w3, '\" при', w1_w2, ': ', model[w1_w2][w3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7oYbFy44uKq"
   },
   "source": [
    "Можете поискать еще интересных сочитаний в модели. Например найти самое часто встречаемое в тексте выражение. Или попробовать использовать пятиграммную модель. Это довольно интересно. \n",
    "\n",
    "Ниже, наконец представлен код для нашей генеративной модели. Рекомендую с ним так же поиграться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qDu_CEdc4uKq",
    "outputId": "98cdeba7-b2f4-4057-bc2a-b905a8cdd630"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У ней ведь был совершенно пьян .\n"
     ]
    }
   ],
   "source": [
    "new_text = [None, None]\n",
    " \n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "    for word in model[tuple(new_text[-2:])].keys():\n",
    "        accumulator += model[tuple(new_text[-2:])][word]\n",
    "        if accumulator >= r:\n",
    "            new_text.append(word)\n",
    "            break\n",
    " \n",
    "    if new_text[-2:] == [None, None]:\n",
    "        sentence_finished = True\n",
    "\n",
    "print(' '.join([t for t in new_text if t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1oUkT7L0DdYN",
    "outputId": "9cc4ceb5-8a6b-4f0d-eb19-23ba9afe1898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я тогда это говорил , что к Кузьме Кузьмичу , к письмоводителю , а все-таки ш-дик : ты видишь , мой друг , до свидания .\n"
     ]
    }
   ],
   "source": [
    "start = 'Я тогда это говорил'\n",
    "\n",
    "new_text = word_tokenize(start)\n",
    " \n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "    r = random.random()\n",
    "    accumulator = .0\n",
    "    for word in model[tuple(new_text[-2:])].keys():\n",
    "        accumulator += model[tuple(new_text[-2:])][word]\n",
    "        if accumulator >= r:\n",
    "            new_text.append(word)\n",
    "            break\n",
    " \n",
    "    if new_text[-2:] == [None, None]:\n",
    "        sentence_finished = True\n",
    "\n",
    "print(' '.join([t for t in new_text if t]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTOGAGFeBMuf"
   },
   "source": [
    "5. Функция для генерации текста по итоговой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxfPHxRVUn10"
   },
   "outputs": [],
   "source": [
    "def gen_text():\n",
    "  new_text = [None, None]\n",
    "  \n",
    "  sentence_finished = False\n",
    "  \n",
    "  while not sentence_finished:\n",
    "      r = random.random()\n",
    "      accumulator = .0\n",
    "      for word in model[tuple(new_text[-2:])].keys():\n",
    "          accumulator += model[tuple(new_text[-2:])][word]\n",
    "          if accumulator >= r:\n",
    "              new_text.append(word)\n",
    "              break\n",
    "  \n",
    "      if new_text[-2:] == [None, None]:\n",
    "          sentence_finished = True\n",
    "\n",
    "  fin = ' '.join([t for t in new_text if t])\n",
    "  #print(fin)\n",
    "  return fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем текст 10 раз и находим самые частые символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "G8MTT2dgUzd4",
    "outputId": "b131d09c-970d-455d-a641-52b49c5757b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наш отпрыск , назад тому полчаса , но и то , что мог ; возлюбив , он уже не направиться к князю Льву Николаевичу , — а это много значит привычка !Он остановился и , наконец , после обеда в семь часов утра к нему еще раз придется развернуть мою рукопись и стали все угождать , стали смеяться : « Эх , барин чаю просит , — прервал Коровкин .Я у вас вовсе не такой… чудак , — закричал хмельной Разумихин , как в европейских литературах были громадной величины художественные гении – Шекспиры , Сервантесы , Шиллеры .— Ба !У Амалии Ивановны .Петр же Ильич , все же произошло затем ?А долго вы изволили тогда приходить , может быть , необходим стал и взял шляпу , она вырывалась из занемевших в отчаянной мольбе защитить , ибо он , должно быть , тут не пошлость эгоизма и желания устроить свою карьеру , выбиться в люди , ну там о каких врагах говорите вы ?Это была тихая , нежная , ясная тишина , с беспокойством , с своей тоской и поминутно преувеличивала беду .С невинною целию обезоружить его либерализмом , он успел и спросить не посмела разбудить .Крест он с ней , — не играет ; но я здесь сижу и никого уже не будем больше жить на свете !\n",
      "5 top characters: [(' ', 217), ('о', 82), ('и', 73), ('е', 69), ('а', 66)]\n"
     ]
    }
   ],
   "source": [
    "all_texts = ''\n",
    "for i in range(10):\n",
    "  all_texts += gen_text()\n",
    "print(all_texts)\n",
    "print ('5 top characters:', Counter(all_texts).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdAL-jmJ4uKs"
   },
   "source": [
    "На данном этапе моедль уже может генерировать более осмысленный текст. Кроме того существует множество статистических методом, которые могают сгладить распределение слов, бороться с появление новых n-грамм. И такие модели до сих пор могут спокойно соревноваться с нейронными решениями. \n",
    "\n",
    "А теперь время для нейросетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVfOD0lw4uKt"
   },
   "source": [
    "## char-RNN in PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soNaU_x24uKt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import codecs\n",
    "import io\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "dYJ5MI1_Ln7p",
    "outputId": "7f4e796c-196c-4968-8119-7bbbe8d8d218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pK4m1Sl54uK3"
   },
   "source": [
    "Закодируем наш текст в цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "UhrbrQ_diHNm",
    "outputId": "64c830f1-2dfd-47a3-cc6f-d0403609153b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-06-05 13:13:12--  https://raw.githubusercontent.com/DLSchool/dlschool_old/master/materials/homeworks/hw09/dostoevsky.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20406049 (19M) [text/plain]\n",
      "Saving to: ‘dostoevsky.txt’\n",
      "\n",
      "dostoevsky.txt      100%[===================>]  19.46M  29.2MB/s    in 0.7s    \n",
      "\n",
      "2020-06-05 13:13:13 (29.2 MB/s) - ‘dostoevsky.txt’ saved [20406049/20406049]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11321980,)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/DLSchool/dlschool_old/master/materials/homeworks/hw09/dostoevsky.txt\n",
    "with io.open('dostoevsky.txt', 'r',encoding='utf8') as f:\n",
    "    text = f.read().replace(u'\\xa0', u' ').replace(u'\\ufeff','')\n",
    "chars = tuple(set(text))\n",
    "int2char = dict(enumerate(chars))\n",
    "char2int = {ch: ii for ii, ch in int2char.items()}\n",
    "encoded = np.array([char2int[ch] for ch in text])\n",
    "encoded.shape # Наш словарь получился очень большой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EKogixrQY9_w",
    "outputId": "3f9c7dab-78c4-481c-dee0-4e6b4d68cc35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsNhlzn34uK8"
   },
   "source": [
    "#### Обработка данных\n",
    "\n",
    "Будем использовать для представления букв one-hot вектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "kEFKzdza84QP",
    "outputId": "ba02f764-000c-450c-bf86-0a0ae401f075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    \n",
    "    # Инициализируем вектора \n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "    \n",
    "    # заполним 1 в соответсвующем месте\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "    \n",
    "    # Приводим к нужному размеру\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "    \n",
    "    return one_hot\n",
    "one_hot_encode(np.array([[4, 0, 3, 2], [1, 1, 3, 3]]), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SLmKXB494uLA"
   },
   "source": [
    "Генератор мини-батчей. Каждая последовательность будет длины `n_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "XWR0XuI14uLA",
    "outputId": "9b5eff65-6b8a-45aa-83da-4488d26cb9ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  9, 161, 142,   0,  85,  84, 149, 167, 168,  23],\n",
       "        [140,   0, 162,  84,  96,   0, 167,  84, 142, 161],\n",
       "        [ 85,  23,  33,   0, 162,  64, 167, 117,  72,  84],\n",
       "        [ 72,  84,  96,  23,  17,   0,  84,  17, 167,  84],\n",
       "        [161, 117, 117,   0,  84, 169, 140, 161,  85, 161],\n",
       "        [ 23,  28,  84,  66,   0,  84,   4,  84, 140,  33],\n",
       "        [ 33,  23,  96,  84, 140, 151,  85,  23, 129, 167],\n",
       "        [ 84, 162,   0,  84, 162,   0,  17,  77,  64,   0]]),\n",
       " array([[161, 142,   0,  85,  84, 149, 167, 168,  23,  68],\n",
       "        [  0, 162,  84,  96,   0, 167,  84, 142, 161, 117],\n",
       "        [ 23,  33,   0, 162,  64, 167, 117,  72,  84,  37],\n",
       "        [ 84,  96,  23,  17,   0,  84,  17, 167,  84, 110],\n",
       "        [117, 117,   0,  84, 169, 140, 161,  85, 161, 117],\n",
       "        [ 28,  84,  66,   0,  84,   4,  84, 140,  33,   4],\n",
       "        [ 23,  96,  84, 140, 151,  85,  23, 129, 167,  17],\n",
       "        [162,   0,  84, 162,   0,  17,  77,  64,   0,  72]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batches(arr, n_seqs, n_steps):\n",
    "    \"\"\"\n",
    "    Создание генератора, возвращающего минибатчи размера (n_seqs x seq_len) Numpy\n",
    "    \"\"\"    \n",
    "    batch_size = n_seqs * n_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size]\n",
    "    # Reshape into n_seqs rows\n",
    "    arr = arr.reshape((n_seqs, -1))\n",
    "    \n",
    "    for n in range(0, arr.shape[1], n_steps):\n",
    "        # The features\n",
    "        x = arr[:, n:n+n_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n+n_steps]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y\n",
    "#check\n",
    "next(get_batches(encoded, 8, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zc1bkSne4uLC"
   },
   "source": [
    "### Построение charRNN модели\n",
    "\n",
    "Почему делаем именно модель над символами? Потому что это очень простая структура, которая может быть применена не только к текстам, но и к музыке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4gJzUB7Qg7nz",
    "outputId": "121ec0e4-9dc3-49c6-e762-42a623208c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU!\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if(train_on_gpu):\n",
    "  print('Training on GPU!')\n",
    "else:\n",
    "  print('Train on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38Qqu4TbMBit"
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, tokens, n_hidden=256, n_layers=2,\n",
    "                               drop_prob=0.2, lr=0.001):\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.chars = tokens\n",
    "        self.int2char = dict(enumerate(self.chars))\n",
    "        self.char2int = {ch: ii for ii, ch in self.int2char.items()}\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob) #<dropout>\n",
    "        self.lstm = nn.LSTM(len(self.chars), n_hidden, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        # self.lstm = nn.GRU(len(self.chars), n_hidden, n_layers,\n",
    "        #                    dropout=drop_prob, batch_first=True) \n",
    "        #<torch gru will be the best choice>\n",
    "        self.fc = nn.Linear(n_hidden, len(self.chars)) #<linear>\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, x, hc):\n",
    "        ''' Forward pass through the network '''\n",
    "        # print (x.shape, hc.shape)\n",
    "        x, h = self.lstm(x, hc)\n",
    "        x = self.dropout(x)\n",
    "        #\n",
    "        x = x.contiguous().view(-1, self.n_hidden)\n",
    "        #\n",
    "        x = self.fc(x)\n",
    "        return x, h\n",
    "    \n",
    "    def predict(self, char, h=None, top_k=None):\n",
    "        \"\"\"        \n",
    "            Returns the predicted character and the hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        if h is None:\n",
    "            h = self.init_hidden(1)#.to(device)\n",
    "        \n",
    "        x = np.array([[self.char2int[char]]])\n",
    "        x =  one_hot_encode(x, len(self.chars)) #<one-hot>\n",
    "        \n",
    "        inputs = torch.from_numpy(x).to(device)\n",
    "        h = tuple([each.data for each in h])\n",
    "        out, h = self.forward(inputs, h)\n",
    "\n",
    "        p = nn.functional.softmax(out, dim=1) #<Get proba vector (softmax on last dimension)>\n",
    "        if(torch.cuda.is_available()):\n",
    "            p = p.cpu() # move to cpu\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(len(self.chars))\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.detach().numpy().squeeze()\n",
    "        # Choose 1/k \n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        \n",
    "        return self.int2char[char], h\n",
    "    \n",
    "    def init_weights(self):\n",
    "        ''' Initialize weights for fully connected layer '''        \n",
    "        # Set bias tensor to all zeros\n",
    "        self.fc.bias.data.fill_(0)\n",
    "        # FC weights as random uniform\n",
    "        self.fc.weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    def init_hidden(self, n_seqs):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        if (torch.cuda.is_available()):\n",
    "            hidden = (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_().cuda()\n",
    "            ,weight.new(self.n_layers, n_seqs, self.n_hidden).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, n_seqs, self.n_hidden).zero_()\n",
    "                      ,weight.new(self.n_layers, n_seqs, self.n_hidden).zero_())\n",
    "        return hidden        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46Q9uU754uLE"
   },
   "source": [
    "Для проверки функционирования у нас есть функция `train` , которая позволит провести большое число экспериментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C99mWJAT4uLE"
   },
   "outputs": [],
   "source": [
    "def train(net, data, epochs=10, n_seqs=10, n_steps=50, lr=0.0005, clip=3, val_frac=0.1, print_every=200):\n",
    "    net.train()\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=lr) #<Optimizer : Adam is the best choice>\n",
    "    criterion = nn.CrossEntropyLoss() #<CE> \n",
    "    \n",
    "    val_idx = int(len(data)*(1-val_frac))\n",
    "    data, val_data = data[:val_idx], data[val_idx:]\n",
    "\n",
    "    if(torch.cuda.is_available()):\n",
    "        net.cuda()\n",
    "    \n",
    "    counter = 0\n",
    "    n_chars = len(net.chars)\n",
    "    for e in range(epochs):\n",
    "        h = net.init_hidden(n_seqs)\n",
    "        for x, y in get_batches(data, n_seqs, n_steps):\n",
    "            counter += 1\n",
    "            \n",
    "            # Кодируем данные и отправлячем\n",
    "            x = one_hot_encode(x, n_chars)\n",
    "            inputs = torch.from_numpy(x).to(device)\n",
    "            targets = torch.from_numpy(y).to(device)\n",
    "            \n",
    "            #  замените на .copy будет работать стабильнее\n",
    "            h = tuple([each.data for each in h])\n",
    "            #tuple([each.data for each in h])\n",
    "            #h.data.clone().detach()\n",
    "            #torch.tensor(h.data, device=device) \n",
    "\n",
    "            net.zero_grad()\n",
    "            \n",
    "            output, h = net.forward(inputs, h)\n",
    "            \n",
    "            loss = criterion(output, targets.view(n_seqs*n_steps)) #.view(n_seqs*n_steps,-1)\n",
    "            loss.backward()\n",
    "            \n",
    "            # clip grad norm может вам помочь\n",
    "            nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "\n",
    "            opt.step()\n",
    "            \n",
    "            if counter % print_every == 0:\n",
    "                net.eval()\n",
    "                # Get validation loss\n",
    "                val_h = net.init_hidden(n_seqs)\n",
    "                val_losses = []\n",
    "                for x, y in get_batches(val_data, n_seqs, n_steps):\n",
    "                    # One-hot encode our data and make them Torch tensors\n",
    "                    x = one_hot_encode(x, n_chars)\n",
    "                    inputs = torch.from_numpy(x).to(device)\n",
    "                    targets = torch.from_numpy(y).to(device)\n",
    "\n",
    "                    # Creating new variables for the hidden state, otherwise\n",
    "                    # we'd backprop through the entire training history\n",
    "                    val_h =tuple([each.data for each in val_h])  # val_h.clone().detach()\n",
    "                    output, val_h = net(inputs, val_h) #net.forward(inputs, val_h)\n",
    "                    val_loss = criterion(output, targets.view(n_seqs*n_steps)) #.view(n_seqs*n_steps,-1)\n",
    "                    val_losses.append(val_loss.item())\n",
    "                   \n",
    "                # Попробуем валидироваться таким способом\n",
    "                prime = 'Дом'\n",
    "                top_k = 4\n",
    "                chars = [ch for ch in prime]\n",
    "                vh = None\n",
    "                for ch in prime:\n",
    "                    char, vh = net.predict(ch, vh, top_k=top_k)\n",
    "                for ii in range(20):\n",
    "                    char, vh = net.predict(chars[-1], vh, top_k=top_k)\n",
    "                    chars.append(char)\n",
    "                    \n",
    "                chars.append(char)\n",
    "                print(' '.join(chars))\n",
    "\n",
    "                net.train()\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.4f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.4f}\".format(np.mean(val_losses)),\n",
    "                       \"Validation Perplexity: {:.4f}\".format(np.exp(np.mean(val_losses))))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvSblHi44uLG"
   },
   "source": [
    "## Время тренировки!\n",
    "\n",
    "![a](https://www.apmpodcasts.org/wp-content/uploads/2015/06/adventure-time.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "qBBOtwJM4uLJ",
    "outputId": "7e162082-4342-4e1a-962a-45c8462bbab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharRNN(\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (lstm): LSTM(175, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=256, out_features=175, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if 'net' in locals():\n",
    "    del net\n",
    "num_hidden_units = 256 #<подберите оптимальное значение (помните, что это буквы)>\n",
    "net = CharRNN(chars, n_hidden=num_hidden_units, n_layers=3).to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gjSO9VtL4uLM",
    "outputId": "cbfe56e9-3cc2-41cd-a26f-4989aaf7d886",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Д о м е н   и   п р о м и   н а   в е р о м н н\n",
      "Epoch: 1/20... Step: 200... Loss: 2.5683... Val Loss: 2.4901 Validation Perplexity: 12.0624\n",
      "Д о м е н н о   с   т о г   с е м и т е л ь н н\n",
      "Epoch: 1/20... Step: 400... Loss: 2.2078... Val Loss: 2.1223 Validation Perplexity: 8.3500\n",
      "Д о м е н и е .   —   А   п р о ч е м ,   п о о\n",
      "Epoch: 1/20... Step: 600... Loss: 2.0503... Val Loss: 1.9138 Validation Perplexity: 6.7787\n",
      "Д о м а н н ы е   и с п р о г и д н о   и ,    \n",
      "Epoch: 1/20... Step: 800... Loss: 1.8988... Val Loss: 1.7950 Validation Perplexity: 6.0195\n",
      "Д о м а н н ы й   и   п о т о в о р н о   с л л\n",
      "Epoch: 1/20... Step: 1000... Loss: 1.7885... Val Loss: 1.7042 Validation Perplexity: 5.4971\n",
      "Д о м е н и я   в   п о м н ю ,   н а   с т р р\n",
      "Epoch: 1/20... Step: 1200... Loss: 1.8199... Val Loss: 1.6472 Validation Perplexity: 5.1926\n",
      "Д о м е н и я   с о с т о я л и с ь   и   в ы ы\n",
      "Epoch: 1/20... Step: 1400... Loss: 1.7288... Val Loss: 1.6087 Validation Perplexity: 4.9963\n",
      "Д о м и ,   в с е   в с е   в   с в е ч у   с с\n",
      "Epoch: 2/20... Step: 1600... Loss: 1.7396... Val Loss: 1.5751 Validation Perplexity: 4.8312\n",
      "Д о м и т ь   н а   м е н я   с о в с е м   н н\n",
      "Epoch: 2/20... Step: 1800... Loss: 1.6345... Val Loss: 1.5546 Validation Perplexity: 4.7332\n",
      "Д о м и т е л ь н о ,   к о т о р ы й   с т а а\n",
      "Epoch: 2/20... Step: 2000... Loss: 1.5848... Val Loss: 1.5276 Validation Perplexity: 4.6072\n",
      "Д о м а ,   п о д   с о б с т в е н н ы м ,    \n",
      "Epoch: 2/20... Step: 2200... Loss: 1.5529... Val Loss: 1.5114 Validation Perplexity: 4.5332\n",
      "Д о м и   с в о е   о б е щ а л   и   с т р а а\n",
      "Epoch: 2/20... Step: 2400... Loss: 1.5743... Val Loss: 1.5013 Validation Perplexity: 4.4874\n",
      "Д о м а   в   к а р т ы н   с т у п е н ь   п п\n",
      "Epoch: 2/20... Step: 2600... Loss: 1.5821... Val Loss: 1.4837 Validation Perplexity: 4.4093\n",
      "Д о м е н и е   с   н о г о м   с о в с е м    \n",
      "Epoch: 2/20... Step: 2800... Loss: 1.5727... Val Loss: 1.4710 Validation Perplexity: 4.3536\n",
      "Д о м у ?   Н у   в ы   н е   в ы   н и к о г г\n",
      "Epoch: 2/20... Step: 3000... Loss: 1.5606... Val Loss: 1.4634 Validation Perplexity: 4.3207\n",
      "Д о м е н и е ,   и   в о т   и   в ы   в о    \n",
      "Epoch: 3/20... Step: 3200... Loss: 1.4775... Val Loss: 1.4524 Validation Perplexity: 4.2734\n",
      "Д о м е н   п о с л е д н е г о ,   н а   с т т\n",
      "Epoch: 3/20... Step: 3400... Loss: 1.5459... Val Loss: 1.4467 Validation Perplexity: 4.2489\n",
      "Д о м е н и я   и   в   п о с м о т р е   в с с\n",
      "Epoch: 3/20... Step: 3600... Loss: 1.4777... Val Loss: 1.4366 Validation Perplexity: 4.2065\n",
      "Д о м е н   и   п о л е з н о е .   В   т о м м\n",
      "Epoch: 3/20... Step: 3800... Loss: 1.4665... Val Loss: 1.4302 Validation Perplexity: 4.1795\n",
      "Д о м е т   с е б я   п о с л е   п а д е н и и\n",
      "Epoch: 3/20... Step: 4000... Loss: 1.5072... Val Loss: 1.4258 Validation Perplexity: 4.1610\n",
      "Д о м и т е л ь н ы е   в о с п о м и н а н н н\n",
      "Epoch: 3/20... Step: 4200... Loss: 1.4693... Val Loss: 1.4201 Validation Perplexity: 4.1375\n",
      "Д о м и л а   с е б я ,   п о   к о т о р о м м\n",
      "Epoch: 3/20... Step: 4400... Loss: 1.4955... Val Loss: 1.4135 Validation Perplexity: 4.1104\n",
      "Д о м у   в   н и х ,   н а к о н е ц ,   в с с\n",
      "Epoch: 3/20... Step: 4600... Loss: 1.4992... Val Loss: 1.4099 Validation Perplexity: 4.0956\n",
      "Д о м и н а ,   н а   в с е х   в о п р о с    \n",
      "Epoch: 4/20... Step: 4800... Loss: 1.4256... Val Loss: 1.4037 Validation Perplexity: 4.0702\n",
      "Д о м е т и н ы .   Н а   к а к   и з   к н я я\n",
      "Epoch: 4/20... Step: 5000... Loss: 1.4986... Val Loss: 1.3990 Validation Perplexity: 4.0511\n",
      "Д о м у   и   с т у п а л .   В о т   т а к    \n",
      "Epoch: 4/20... Step: 5200... Loss: 1.3836... Val Loss: 1.3936 Validation Perplexity: 4.0293\n",
      "Д о м и н а   и   в   с в е т е   в с т а л а а\n",
      "Epoch: 4/20... Step: 5400... Loss: 1.3895... Val Loss: 1.3902 Validation Perplexity: 4.0155\n",
      "Д о м а   и   в е с ь м а   н е   п о д н я в в\n",
      "Epoch: 4/20... Step: 5600... Loss: 1.4224... Val Loss: 1.3880 Validation Perplexity: 4.0069\n",
      "Д о м у   и   н е   п р а в д у ,   н о ,   п п\n",
      "Epoch: 4/20... Step: 5800... Loss: 1.4199... Val Loss: 1.3830 Validation Perplexity: 3.9869\n",
      "Д о м е р   п о   к р а й н е й   м е р е ,    \n",
      "Epoch: 4/20... Step: 6000... Loss: 1.5109... Val Loss: 1.3781 Validation Perplexity: 3.9672\n",
      "Д о м е н   и   в   с е б е   в   с о в е р ш ш\n",
      "Epoch: 4/20... Step: 6200... Loss: 1.4104... Val Loss: 1.3771 Validation Perplexity: 3.9632\n",
      "Д о м и н у ,   н е   з а м е т ь т е ,   к    \n",
      "Epoch: 5/20... Step: 6400... Loss: 1.3964... Val Loss: 1.3728 Validation Perplexity: 3.9466\n",
      "Д о м у .   Н у ,   п о т о м у   ч т о   я    \n",
      "Epoch: 5/20... Step: 6600... Loss: 1.4364... Val Loss: 1.3698 Validation Perplexity: 3.9346\n",
      "Д о м у   и   п о д л е   с в е т л ы х   с о о\n",
      "Epoch: 5/20... Step: 6800... Loss: 1.4129... Val Loss: 1.3675 Validation Perplexity: 3.9254\n",
      "Д о м и т е л ь н ы й   п о л о в и н у   п о о\n",
      "Epoch: 5/20... Step: 7000... Loss: 1.4296... Val Loss: 1.3642 Validation Perplexity: 3.9127\n",
      "Д о м у   в с е г д а   п р е д л ы х а л и , ,\n",
      "Epoch: 5/20... Step: 7200... Loss: 1.3812... Val Loss: 1.3631 Validation Perplexity: 3.9082\n",
      "Д о м у   в   н о ч и   с   н е й   с о с т а а\n",
      "Epoch: 5/20... Step: 7400... Loss: 1.4102... Val Loss: 1.3586 Validation Perplexity: 3.8907\n",
      "Д о м е ц ,   н е   с т а н е т   в с е м   с с\n",
      "Epoch: 5/20... Step: 7600... Loss: 1.3899... Val Loss: 1.3587 Validation Perplexity: 3.8910\n",
      "Д о м а л ь с к о г о   с о б о ю .   В о т    \n",
      "Epoch: 5/20... Step: 7800... Loss: 1.4086... Val Loss: 1.3555 Validation Perplexity: 3.8785\n",
      "Д о м е н т о в ,   и   в с е   э т о   н а п п\n",
      "Epoch: 6/20... Step: 8000... Loss: 1.4167... Val Loss: 1.3534 Validation Perplexity: 3.8708\n",
      "Д о м е с т и ч е с к и   с   н и м   в о з ь ь\n",
      "Epoch: 6/20... Step: 8200... Loss: 1.3815... Val Loss: 1.3504 Validation Perplexity: 3.8591\n",
      "Д о м е н т а   п р е д п о л о ж и т ь   с    \n",
      "Epoch: 6/20... Step: 8400... Loss: 1.4281... Val Loss: 1.3512 Validation Perplexity: 3.8621\n",
      "Д о м е р   с т а р о с т и   с т о я в ш е г г\n",
      "Epoch: 6/20... Step: 8600... Loss: 1.3522... Val Loss: 1.3469 Validation Perplexity: 3.8453\n",
      "Д о м у   и   п р о   с е б я . \n",
      " —   Н е т , ,\n",
      "Epoch: 6/20... Step: 8800... Loss: 1.3368... Val Loss: 1.3497 Validation Perplexity: 3.8561\n",
      "Д о м у   и ,   п р и н я в   н е   в е с ь м м\n",
      "Epoch: 6/20... Step: 9000... Loss: 1.3729... Val Loss: 1.3450 Validation Perplexity: 3.8384\n",
      "Д о м а т и ч е с к о й ,   н а   п р о т и в в\n",
      "Epoch: 6/20... Step: 9200... Loss: 1.3584... Val Loss: 1.3430 Validation Perplexity: 3.8307\n",
      "Д о м е н т у ю щ е е   и   в   т о т   с т р р\n",
      "Epoch: 6/20... Step: 9400... Loss: 1.3581... Val Loss: 1.3411 Validation Perplexity: 3.8232\n",
      "Д о м у ,   в с е   с т а р ш и е   в с е х    \n",
      "Epoch: 7/20... Step: 9600... Loss: 1.3256... Val Loss: 1.3404 Validation Perplexity: 3.8204\n",
      "Д о м и н у   и   п р о с и т е л ь н о   в    \n",
      "Epoch: 7/20... Step: 9800... Loss: 1.3486... Val Loss: 1.3378 Validation Perplexity: 3.8106\n",
      "Д о м и   п о   п о с т е л ь ,   и з   н а ш ш\n",
      "Epoch: 7/20... Step: 10000... Loss: 1.3384... Val Loss: 1.3367 Validation Perplexity: 3.8064\n",
      "Д о м е н н у ю   и д е ю ,   а   п р е д   в в\n",
      "Epoch: 7/20... Step: 10200... Loss: 1.3418... Val Loss: 1.3345 Validation Perplexity: 3.7979\n",
      "Д о м е с т е р   и   в о   с н е   н е   п о о\n",
      "Epoch: 7/20... Step: 10400... Loss: 1.3228... Val Loss: 1.3355 Validation Perplexity: 3.8020\n",
      "Д о м е н н ы й   и   н е   в и д и т   в а с с\n",
      "Epoch: 7/20... Step: 10600... Loss: 1.3825... Val Loss: 1.3330 Validation Perplexity: 3.7925\n",
      "Д о м е н н ы е   и   в е щ и   и   н е   б ы ы\n",
      "Epoch: 7/20... Step: 10800... Loss: 1.4006... Val Loss: 1.3320 Validation Perplexity: 3.7887\n",
      "Д о м и л а   с в о и х   в о с п и т а н и й й\n",
      "Epoch: 7/20... Step: 11000... Loss: 1.3385... Val Loss: 1.3289 Validation Perplexity: 3.7770\n",
      "Д о м и л о в а ,   к о т о р ы е   п о с к о о\n",
      "Epoch: 8/20... Step: 11200... Loss: 1.3353... Val Loss: 1.3284 Validation Perplexity: 3.7750\n",
      "Д о м и т е л ь . \n",
      " —   Д а ,   в е р о я т н н\n",
      "Epoch: 8/20... Step: 11400... Loss: 1.3686... Val Loss: 1.3267 Validation Perplexity: 3.7685\n",
      "Д о м у   с в о и ,   н о   н е   п р и   в с с\n",
      "Epoch: 8/20... Step: 11600... Loss: 1.3245... Val Loss: 1.3259 Validation Perplexity: 3.7654\n",
      "Д о м у   и   п о д о з р е в а л   в   т а к к\n",
      "Epoch: 8/20... Step: 11800... Loss: 1.3489... Val Loss: 1.3249 Validation Perplexity: 3.7617\n",
      "Д о м е с т и ч е с к о й   и   п о л о в и н н\n",
      "Epoch: 8/20... Step: 12000... Loss: 1.3787... Val Loss: 1.3257 Validation Perplexity: 3.7647\n",
      "Д о м у   в с е   э т о   с а м о е   с о в е е\n",
      "Epoch: 8/20... Step: 12200... Loss: 1.3715... Val Loss: 1.3233 Validation Perplexity: 3.7557\n",
      "Д о м и   и   в   п о д л е ц о м ,   и з в е е\n",
      "Epoch: 8/20... Step: 12400... Loss: 1.3510... Val Loss: 1.3230 Validation Perplexity: 3.7546\n",
      "Д о м а   в с е х   с о с т а в л я л   с е й й\n",
      "Epoch: 8/20... Step: 12600... Loss: 1.3910... Val Loss: 1.3209 Validation Perplexity: 3.7468\n",
      "Д о м и т е р н о   с о б с т в е н н о   п о о\n",
      "Epoch: 9/20... Step: 12800... Loss: 1.3633... Val Loss: 1.3201 Validation Perplexity: 3.7438\n",
      "Д о м у ,   п е р е м о г а е т   и   в   с е е\n",
      "Epoch: 9/20... Step: 13000... Loss: 1.3325... Val Loss: 1.3192 Validation Perplexity: 3.7405\n",
      "Д о м а т а   и   с т а л о   б ы   п р е д    \n",
      "Epoch: 9/20... Step: 13200... Loss: 1.3395... Val Loss: 1.3166 Validation Perplexity: 3.7306\n",
      "Д о м и н с к о г о   в   п о р т р о н с к о о\n",
      "Epoch: 9/20... Step: 13400... Loss: 1.3404... Val Loss: 1.3177 Validation Perplexity: 3.7347\n",
      "Д о м и н е н к у .   Н о   т е б е   н а д о о\n",
      "Epoch: 9/20... Step: 13600... Loss: 1.3969... Val Loss: 1.3173 Validation Perplexity: 3.7335\n",
      "Д о м у   с т а в к и ,   н о ,   п р и с т а а\n",
      "Epoch: 9/20... Step: 13800... Loss: 1.3483... Val Loss: 1.3149 Validation Perplexity: 3.7244\n",
      "Д о м у   и   с а м о е   в р е м я ,   и   п п\n",
      "Epoch: 9/20... Step: 14000... Loss: 1.3140... Val Loss: 1.3148 Validation Perplexity: 3.7241\n",
      "Д о м а н и я   и   н е   с о в е р ш е н н о о\n",
      "Epoch: 9/20... Step: 14200... Loss: 1.3697... Val Loss: 1.3137 Validation Perplexity: 3.7199\n",
      "Д о м е т е н т н ы й   с т а р и к   с   т о о\n",
      "Epoch: 10/20... Step: 14400... Loss: 1.3340... Val Loss: 1.3129 Validation Perplexity: 3.7168\n",
      "Д о м у ,   и   с т р а д а н и е ,   н о ,    \n",
      "Epoch: 10/20... Step: 14600... Loss: 1.4105... Val Loss: 1.3131 Validation Perplexity: 3.7178\n",
      "Д о м а л с я   и ,   н а п р о т и в ,   с о о\n",
      "Epoch: 10/20... Step: 14800... Loss: 1.3428... Val Loss: 1.3105 Validation Perplexity: 3.7079\n",
      "Д о м у ,   н о   в о з м о ж н о   п о д о б б\n",
      "Epoch: 10/20... Step: 15000... Loss: 1.3346... Val Loss: 1.3098 Validation Perplexity: 3.7055\n",
      "Д о м у   и   с   п е р в о г о   в з г л я д д\n",
      "Epoch: 10/20... Step: 15200... Loss: 1.3341... Val Loss: 1.3110 Validation Perplexity: 3.7098\n",
      "Д о м у   и   н а   п о л ь з у ,   п р о с т т\n",
      "Epoch: 10/20... Step: 15400... Loss: 1.3633... Val Loss: 1.3082 Validation Perplexity: 3.6995\n",
      "Д о м е н н ы й   и   н е о п р и м е р ,   и и\n",
      "Epoch: 10/20... Step: 15600... Loss: 1.2919... Val Loss: 1.3086 Validation Perplexity: 3.7011\n",
      "Д о м у   п о д   к р а й н е й   с е м ь е    \n",
      "Epoch: 10/20... Step: 15800... Loss: 1.3294... Val Loss: 1.3078 Validation Perplexity: 3.6980\n",
      "Д о м е н а   п о   в о л н е н и ю .   Н о    \n",
      "Epoch: 11/20... Step: 16000... Loss: 1.3477... Val Loss: 1.3063 Validation Perplexity: 3.6924\n",
      "Д о м у   в   п о д л о с т и ,   и   н е   с с\n",
      "Epoch: 11/20... Step: 16200... Loss: 1.3410... Val Loss: 1.3067 Validation Perplexity: 3.6940\n",
      "Д о м у ,   п о с л е   с т р а х у ,   в о т т\n",
      "Epoch: 11/20... Step: 16400... Loss: 1.3591... Val Loss: 1.3040 Validation Perplexity: 3.6842\n",
      "Д о м е н т а   в   п о с л е д н и й   р а з з\n",
      "Epoch: 11/20... Step: 16600... Loss: 1.3091... Val Loss: 1.3036 Validation Perplexity: 3.6827\n",
      "Д о м а   и   н и ч е г о ,   к о г д а   я    \n",
      "Epoch: 11/20... Step: 16800... Loss: 1.3812... Val Loss: 1.3051 Validation Perplexity: 3.6881\n",
      "Д о м е т е н т   и з   к а р м а н а   н а с с\n",
      "Epoch: 11/20... Step: 17000... Loss: 1.3050... Val Loss: 1.3036 Validation Perplexity: 3.6826\n",
      "Д о м е с и я ,   н е   с л ы х а в   с е б я я\n",
      "Epoch: 11/20... Step: 17200... Loss: 1.3211... Val Loss: 1.3034 Validation Perplexity: 3.6817\n",
      "Д о м е н е ,   в   к а к о м - т о   с о в е е\n",
      "Epoch: 11/20... Step: 17400... Loss: 1.3390... Val Loss: 1.3019 Validation Perplexity: 3.6764\n",
      "Д о м у   и   с а м о е   н е с ч а с т н о е е\n",
      "Epoch: 12/20... Step: 17600... Loss: 1.3089... Val Loss: 1.3019 Validation Perplexity: 3.6764\n",
      "Д о м а   и   п о с т а в и л   е м у   в   п п\n",
      "Epoch: 12/20... Step: 17800... Loss: 1.3329... Val Loss: 1.3020 Validation Perplexity: 3.6765\n",
      "Д о м у ,   и   с   с а м ы м   в и н о в н ы ы\n",
      "Epoch: 12/20... Step: 18000... Loss: 1.3105... Val Loss: 1.2978 Validation Perplexity: 3.6613\n",
      "Д о м и с о в а   и   с   н и м ,   к о г д а а\n",
      "Epoch: 12/20... Step: 18200... Loss: 1.2886... Val Loss: 1.3001 Validation Perplexity: 3.6698\n",
      "Д о м у ,   и з   н а с л а ж д е н и й .   В В\n",
      "Epoch: 12/20... Step: 18400... Loss: 1.3189... Val Loss: 1.2990 Validation Perplexity: 3.6656\n",
      "Д о м у ,   н а   к р а ю   в   к а р м а н , ,\n",
      "Epoch: 12/20... Step: 18600... Loss: 1.3370... Val Loss: 1.2977 Validation Perplexity: 3.6610\n",
      "Д о м у ,   и   н и к а к   н е   з н а л ,    \n",
      "Epoch: 12/20... Step: 18800... Loss: 1.3507... Val Loss: 1.2987 Validation Perplexity: 3.6645\n",
      "Д о м а ,   н е   б у д у   с   т о л к у   с с\n",
      "Epoch: 12/20... Step: 19000... Loss: 1.3202... Val Loss: 1.2968 Validation Perplexity: 3.6575\n",
      "Д о м е т   в   с е б я   в   п о р у ч е н и и\n",
      "Epoch: 13/20... Step: 19200... Loss: 1.3092... Val Loss: 1.2970 Validation Perplexity: 3.6585\n",
      "Д о м е т а л ь н и к о в   в   п о л о ж е н н\n",
      "Epoch: 13/20... Step: 19400... Loss: 1.2964... Val Loss: 1.2990 Validation Perplexity: 3.6655\n",
      "Д о м у ,   и   в с е   в с е   э т и   д е н н\n",
      "Epoch: 13/20... Step: 19600... Loss: 1.3314... Val Loss: 1.2936 Validation Perplexity: 3.6457\n",
      "Д о м у   с в о и м .   О н ,   к а ж е т с я я\n",
      "Epoch: 13/20... Step: 19800... Loss: 1.3185... Val Loss: 1.2947 Validation Perplexity: 3.6500\n",
      "Д о м е   П е т р о в и ч а   и   п о т о м у у\n",
      "Epoch: 13/20... Step: 20000... Loss: 1.3371... Val Loss: 1.2949 Validation Perplexity: 3.6506\n",
      "Д о м е н н ы й   с о б о ю ,   н и   п р е д д\n",
      "Epoch: 13/20... Step: 20200... Loss: 1.2976... Val Loss: 1.2938 Validation Perplexity: 3.6467\n",
      "Д о м е т и й ,   п р и   в с е м   с л у ч а а\n",
      "Epoch: 13/20... Step: 20400... Loss: 1.3220... Val Loss: 1.2919 Validation Perplexity: 3.6397\n",
      "Д о м у   с в о и м   и   с т р е м л е н и е е\n",
      "Epoch: 13/20... Step: 20600... Loss: 1.3244... Val Loss: 1.2932 Validation Perplexity: 3.6445\n",
      "Д о м е н а   с   т е м   ч т о б ы   в ы с к к\n",
      "Epoch: 14/20... Step: 20800... Loss: 1.3105... Val Loss: 1.2934 Validation Perplexity: 3.6452\n",
      "Д о м у . \n",
      " —   Д а ,   д е с к а т ь ,   я    \n",
      "Epoch: 14/20... Step: 21000... Loss: 1.3058... Val Loss: 1.2933 Validation Perplexity: 3.6449\n",
      "Д о м у   с о в с е м   н е   с о в с е м   п п\n",
      "Epoch: 14/20... Step: 21200... Loss: 1.3137... Val Loss: 1.2909 Validation Perplexity: 3.6359\n",
      "Д о м е н а .   П о т о м   п р е д   т о б о о\n",
      "Epoch: 14/20... Step: 21400... Loss: 1.2977... Val Loss: 1.2916 Validation Perplexity: 3.6386\n",
      "Д о м е р и а   и   с т о л ь   н а д о   б о о\n",
      "Epoch: 14/20... Step: 21600... Loss: 1.3324... Val Loss: 1.2912 Validation Perplexity: 3.6371\n",
      "Д о м е н а   и   н е   с л у ш а л а ,   а    \n",
      "Epoch: 14/20... Step: 21800... Loss: 1.3459... Val Loss: 1.2906 Validation Perplexity: 3.6349\n",
      "Д о м е н н о г о ,   н о   о н   н и к о г д д\n",
      "Epoch: 14/20... Step: 22000... Loss: 1.3169... Val Loss: 1.2913 Validation Perplexity: 3.6374\n",
      "Д о м а ,   п р о с т о   с к а ж е т ,   ч т т\n",
      "Epoch: 14/20... Step: 22200... Loss: 1.3095... Val Loss: 1.2913 Validation Perplexity: 3.6376\n",
      "Д о м е н а   П е т р о в и ч а .   В   к о т т\n",
      "Epoch: 15/20... Step: 22400... Loss: 1.2946... Val Loss: 1.2908 Validation Perplexity: 3.6356\n",
      "Д о м у ,   н е   о п а с н о с т ь   н е   м м\n",
      "Epoch: 15/20... Step: 22600... Loss: 1.3603... Val Loss: 1.2912 Validation Perplexity: 3.6372\n",
      "Д о м у   и з - з а   н е е   с л у ч и т ь с с\n",
      "Epoch: 15/20... Step: 22800... Loss: 1.2745... Val Loss: 1.2887 Validation Perplexity: 3.6281\n",
      "Д о м у ,   в   п е р в ы й   р а з   в   п о о\n",
      "Epoch: 15/20... Step: 23000... Loss: 1.3087... Val Loss: 1.2894 Validation Perplexity: 3.6307\n",
      "Д о м у   и   н а   с е б я   в   п р е ж н и и\n",
      "Epoch: 15/20... Step: 23200... Loss: 1.2601... Val Loss: 1.2902 Validation Perplexity: 3.6336\n",
      "Д о м у   в с ю   н о ч ь   н а д о   в с ё    \n",
      "Epoch: 15/20... Step: 23400... Loss: 1.3257... Val Loss: 1.2873 Validation Perplexity: 3.6231\n",
      "Д о м у   и   с   н и м и   с   п р о с т о д д\n",
      "Epoch: 15/20... Step: 23600... Loss: 1.3205... Val Loss: 1.2874 Validation Perplexity: 3.6232\n",
      "Д о м е н ь к у ,   и з   с о б ы т и й   и    \n",
      "Epoch: 15/20... Step: 23800... Loss: 1.2871... Val Loss: 1.2878 Validation Perplexity: 3.6247\n",
      "Д о м у .   Н а к о н е ц ,   о д н а к о   ж ж\n",
      "Epoch: 16/20... Step: 24000... Loss: 1.2697... Val Loss: 1.2883 Validation Perplexity: 3.6265\n",
      "Д о м а с и ю   и   н е п р и м е т н о .   В В\n",
      "Epoch: 16/20... Step: 24200... Loss: 1.2866... Val Loss: 1.2883 Validation Perplexity: 3.6266\n",
      "Д о м а с и я   п о д   в ы с ш и х   д е л а а\n",
      "Epoch: 16/20... Step: 24400... Loss: 1.3063... Val Loss: 1.2875 Validation Perplexity: 3.6238\n",
      "Д о м е р и у   п е р е с к о ч и л . \n",
      " —   А А\n",
      "Epoch: 16/20... Step: 24600... Loss: 1.2895... Val Loss: 1.2873 Validation Perplexity: 3.6231\n",
      "Д о м у   п р и ш е л   к   н и м   н е   м о о\n",
      "Epoch: 16/20... Step: 24800... Loss: 1.2595... Val Loss: 1.2866 Validation Perplexity: 3.6206\n",
      "Д о м е   П е т р о в и ч а ,   и   в с е   с с\n",
      "Epoch: 16/20... Step: 25000... Loss: 1.3015... Val Loss: 1.2851 Validation Perplexity: 3.6152\n",
      "Д о м у .   Н а п р и м е р ,   о н ,   н е    \n",
      "Epoch: 16/20... Step: 25200... Loss: 1.2585... Val Loss: 1.2842 Validation Perplexity: 3.6118\n",
      "Д о м е н т у   и   н а д о   м н о й   п р о о\n",
      "Epoch: 16/20... Step: 25400... Loss: 1.3117... Val Loss: 1.2843 Validation Perplexity: 3.6122\n",
      "Д о м е т а н с к о г о   п и с ь м а   в   т т\n",
      "Epoch: 17/20... Step: 25600... Loss: 1.3114... Val Loss: 1.2848 Validation Perplexity: 3.6138\n",
      "Д о м е   П о р ф и р и е м ,   п о   п р о с с\n",
      "Epoch: 17/20... Step: 25800... Loss: 1.2801... Val Loss: 1.2859 Validation Perplexity: 3.6181\n",
      "Д о м а т с и е   и   н и к т о   н е   с о в в\n",
      "Epoch: 17/20... Step: 26000... Loss: 1.2987... Val Loss: 1.2831 Validation Perplexity: 3.6077\n",
      "Д о м и с е р   и   с а м   п о с л е   с е б б\n",
      "Epoch: 17/20... Step: 26200... Loss: 1.3290... Val Loss: 1.2840 Validation Perplexity: 3.6112\n",
      "Д о м е н т а   с т а р у ш к и ,   к а к   в в\n",
      "Epoch: 17/20... Step: 26400... Loss: 1.2728... Val Loss: 1.2833 Validation Perplexity: 3.6086\n",
      "Д о м у   п о   к р а й н е й   м е р е   в    \n",
      "Epoch: 17/20... Step: 26600... Loss: 1.3388... Val Loss: 1.2798 Validation Perplexity: 3.5960\n",
      "Д о м у   в   с в о е й   к р а с а в и ч е с с\n",
      "Epoch: 17/20... Step: 26800... Loss: 1.3020... Val Loss: 1.2811 Validation Perplexity: 3.6005\n",
      "Д о м е с т у р н ы й   с т р а н н ы й   и    \n",
      "Epoch: 17/20... Step: 27000... Loss: 1.3043... Val Loss: 1.2800 Validation Perplexity: 3.5965\n",
      "Д о м е р е в а ,   п о с л е   т а к о г о    \n",
      "Epoch: 18/20... Step: 27200... Loss: 1.3377... Val Loss: 1.2814 Validation Perplexity: 3.6016\n",
      "Д о м у   п о   к р е д и т о к ,   к о т о р р\n",
      "Epoch: 18/20... Step: 27400... Loss: 1.3162... Val Loss: 1.2818 Validation Perplexity: 3.6029\n",
      "Д о м е   с в о и м   в   с в о е й   к р е д д\n",
      "Epoch: 18/20... Step: 27600... Loss: 1.2633... Val Loss: 1.2811 Validation Perplexity: 3.6006\n",
      "Д о м е н т н е й ш а я   с о л н ц а ,   и з з\n",
      "Epoch: 18/20... Step: 27800... Loss: 1.2608... Val Loss: 1.2807 Validation Perplexity: 3.5993\n",
      "Д о м е ,   н а п е р е д   н е   м о г   с к к\n",
      "Epoch: 18/20... Step: 28000... Loss: 1.3094... Val Loss: 1.2804 Validation Perplexity: 3.5981\n",
      "Д о м е   К о л я   в   п о л к о в н и к е    \n",
      "Epoch: 18/20... Step: 28200... Loss: 1.3175... Val Loss: 1.2788 Validation Perplexity: 3.5924\n",
      "Д о м а д с к о г о   и   н е   в ы с к а з а а\n",
      "Epoch: 18/20... Step: 28400... Loss: 1.3327... Val Loss: 1.2794 Validation Perplexity: 3.5946\n",
      "Д о м а   и   с т о и т   н а   п р о с т о й й\n",
      "Epoch: 18/20... Step: 28600... Loss: 1.3227... Val Loss: 1.2800 Validation Perplexity: 3.5965\n",
      "Д о м е   П а р ф е н о в и ч а   н е с м о т т\n",
      "Epoch: 19/20... Step: 28800... Loss: 1.3192... Val Loss: 1.2787 Validation Perplexity: 3.5921\n",
      "Д о м у .   О н а   п о д н я л а с ь   и   в в\n",
      "Epoch: 19/20... Step: 29000... Loss: 1.2705... Val Loss: 1.2802 Validation Perplexity: 3.5973\n",
      "Д о м у   и   в с е х   п о л о т и т ь   с в в\n",
      "Epoch: 19/20... Step: 29200... Loss: 1.2574... Val Loss: 1.2806 Validation Perplexity: 3.5988\n",
      "Д о м у   с о с т а в л я л   н а   н о в у ю ю\n",
      "Epoch: 19/20... Step: 29400... Loss: 1.2831... Val Loss: 1.2775 Validation Perplexity: 3.5875\n",
      "Д о м а с ь е   И в а н о в и ч у . \n",
      " —   А    \n",
      "Epoch: 19/20... Step: 29600... Loss: 1.3162... Val Loss: 1.2763 Validation Perplexity: 3.5833\n",
      "Д о м у .   В ы   с о в е р ш е н н о   с к о о\n",
      "Epoch: 19/20... Step: 29800... Loss: 1.2667... Val Loss: 1.2765 Validation Perplexity: 3.5842\n",
      "Д о м е р и я   и   н а п р а с н о   п о д а а\n",
      "Epoch: 19/20... Step: 30000... Loss: 1.2468... Val Loss: 1.2770 Validation Perplexity: 3.5858\n",
      "Д о м е с т а ,   н е   о б ъ я в и л а ,   ч ч\n",
      "Epoch: 19/20... Step: 30200... Loss: 1.2541... Val Loss: 1.2751 Validation Perplexity: 3.5790\n",
      "Д о м у   П е т р о в и ч у ,   п о   к р а й й\n",
      "Epoch: 20/20... Step: 30400... Loss: 1.3174... Val Loss: 1.2761 Validation Perplexity: 3.5826\n",
      "Д о м у !   В с е г о   д в а д ц а т ь   т ы ы\n",
      "Epoch: 20/20... Step: 30600... Loss: 1.3109... Val Loss: 1.2794 Validation Perplexity: 3.5943\n",
      "Д о м а с и я   п о д   к о н е ц   о б о з н н\n",
      "Epoch: 20/20... Step: 30800... Loss: 1.3041... Val Loss: 1.2760 Validation Perplexity: 3.5822\n",
      "Д о м у ,   н а   м и н у т у   н а ч а л   с с\n",
      "Epoch: 20/20... Step: 31000... Loss: 1.2769... Val Loss: 1.2765 Validation Perplexity: 3.5840\n",
      "Д о м е с ь   и   с   с а м о г о   н а ч а л л\n",
      "Epoch: 20/20... Step: 31200... Loss: 1.2960... Val Loss: 1.2759 Validation Perplexity: 3.5819\n",
      "Д о м у ,   н а д о   б ы л о   п р о д о л ж ж\n",
      "Epoch: 20/20... Step: 31400... Loss: 1.2724... Val Loss: 1.2740 Validation Perplexity: 3.5753\n",
      "Д о м е р у   и   п о д с л у ш а в ш и м   и и\n",
      "Epoch: 20/20... Step: 31600... Loss: 1.2929... Val Loss: 1.2739 Validation Perplexity: 3.5746\n",
      "Д о м е н т а л ь н о г о   в   т а к о м   в в\n",
      "Epoch: 20/20... Step: 31800... Loss: 1.2820... Val Loss: 1.2748 Validation Perplexity: 3.5780\n",
      "CPU times: user 19min 39s, sys: 4min 41s, total: 24min 21s\n",
      "Wall time: 24min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(net, encoded, epochs=20,\n",
    "      n_seqs=64, n_steps=100, lr=0.001, \n",
    "      print_every=200)\n",
    "\n",
    "checkpoint = {'n_hidden': net.n_hidden,\n",
    "              'n_layers': net.n_layers,\n",
    "              'state_dict': net.state_dict(),\n",
    "              'tokens': net.chars}\n",
    "\n",
    "model_save_name = 'LSTM-20epochs.net'\n",
    "with open(f'/content/gdrive/My Drive/Char-RNN/{model_save_name}', 'wb') as f:\n",
    "    torch.save(checkpoint, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z58nbn9Ph6AI"
   },
   "source": [
    "Целая часть итоговой перплексии: **3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGHV-y2d4uLQ"
   },
   "source": [
    "### Загрузка модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76hVSahj4uLQ"
   },
   "source": [
    "После обучения мы сохраним модель, чтобы мы могли загрузить ее позже, если понадобится. Здесь сохраняются параметры, необходимые для создания той же архитектуры, гиперпараметров скрытого слоя и текстовых символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VunUHUjt81IQ",
    "outputId": "51c0295a-860f-43c7-a0a8-e375a6e86741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_name = 'LSTM-20epochs.net'\n",
    "with open(f'/content/gdrive/My Drive/Char-RNN/{model_save_name}', 'rb') as f:\n",
    "    checkpoint = torch.load(f, map_location=torch.device('cpu'))\n",
    "    \n",
    "loaded = CharRNN(checkpoint['tokens'], n_hidden=checkpoint['n_hidden'], n_layers=checkpoint['n_layers'])\n",
    "loaded.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "#check forward pass:\n",
    "# char = chars[5]\n",
    "# x = np.array([[char2int[char]]])\n",
    "# x =  one_hot_encode(x, len(chars)) #<one-hot>\n",
    "# loaded.forward(torch.from_numpy(x).to(device),\n",
    "#                tuple([each.data for each in loaded.init_hidden(1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmMeiwj_4uLU"
   },
   "source": [
    "### Сэмплирование, Top K method\n",
    "\n",
    "Наши прогнозы основаны на категориальном распределении вероятностей по всем возможным признакам. Делаем выборку, учитывая только некоторые вероятные символы $ K $, чтобы сеть не давала нам абсолютно абсурдные символы, вводя некоторый шум и случайность в выбранный текст.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9nLlCmPO4uLV"
   },
   "outputs": [],
   "source": [
    "def sample(net, size, prime='The', top_k=None, cuda=False):\n",
    "    net.eval()\n",
    "    # First off, run through the prime characters\n",
    "    chars = [ch for ch in prime]\n",
    "    h = None\n",
    "    for ch in prime:\n",
    "        char, h = net.predict(ch, h,top_k=top_k)\n",
    "        \n",
    "    chars.append(char)\n",
    "    \n",
    "    # Now pass in the previous character and get a new one\n",
    "    for ii in range(size):\n",
    "        char, h = net.predict(chars[-1], h, top_k=top_k)\n",
    "        chars.append(char)\n",
    "\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F83uekj74uLU"
   },
   "source": [
    "Пример работы модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u6toyTr04uLX",
    "outputId": "a14c88b2-f209-4204-c25c-39af015263fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путинский и под конец в своем получении своей подлости и с необходимыми, но в таком случае она приняла его\n"
     ]
    }
   ],
   "source": [
    "loaded.eval()\n",
    "print(sample(loaded, 100, prime='Путин', top_k=2, cuda=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ISqy7dUYFyf"
   },
   "source": [
    "Посмотрим на семлы случайной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CE_omhdlFnjs",
    "outputId": "26401899-51fe-4c18-d1f2-07f75b127df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Путин ЦVМЦ»ШЦ»VVШМШШ»ЦМVШШМ\n"
     ]
    }
   ],
   "source": [
    "print(sample(CharRNN(chars, n_hidden=256, n_layers=2).to(device), \n",
    "             20, prime='Путин ', top_k=5, cuda=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ep25-RYYJEW"
   },
   "source": [
    "Разница видна, значит мы все сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "m6i9_OHnbinH",
    "outputId": "ecedaf48-e615-47ab-82cb-c4ce15d1309c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Раз два рубля на минуту, например, через них, в каком странной вере не может быть, чтоб ответил в темноте и потому принимался в нем на себя. Но теперь они становилось с того часа на дому, и все время не совсем не вынесла и выставилась в корнести и послышались на половине своего последнего вопроса, но на стуле и поступила в комнату, и отвечают на нее вопросы. Она подала ему всем восторгом. Вот тогда все выходят. В самом деле, когда он пришел к нему в сердце, но никак не мог послать на мою кровь в карман в подлость, и он в самом деле, и почему-то все это подозрилось на своей крайности. Она выслушала, как бы в сторону происхадивший в своих словах, и всегда, при всех отца от него наши слова старуха, и он просто страдал и в такой стороне несколько слов в странном смысле, что в том, что она сама пред нею совершенно понимаю и про себя начинала, не сознала вас в настоящих случаях, и перед вами представлялось в том, что в самых делах состоил в таком постель, и всегда принимается в свои два месяца, всем\n"
     ]
    }
   ],
   "source": [
    "print(sample(loaded, 1000, top_k=3, prime=\"Раз два\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dk1pTb2TAilb"
   },
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQHOgmuUoZgB"
   },
   "source": [
    "Варьирование параметров n_seqs, n_steps, n_layers и num_hidden_units не дало какого-то ощутимого падения итоговой перплексии, все сходилось к значению **3,5-3,8**. Кол-во эпох больше 20 особого прироста качества не принесло. Также не получилось обучить сеть с ячейкой GRU вместо LSTM - перплексия падала, но сэмплы модели давали предикты только на несколько возможных символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAgMGsvqrKV3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of [hw]LanguageModel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
